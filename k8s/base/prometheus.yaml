---
# =======================================================================
# Prometheus — Metrics collection and alerting (90-day retention)
# =======================================================================
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: iot-meter
  labels:
    app: prometheus
    app.kubernetes.io/part-of: iot-meter

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
  labels:
    app: prometheus
rules:
  - apiGroups: [""]
    resources:
      - nodes
      - nodes/metrics
      - services
      - endpoints
      - pods
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources:
      - configmaps
    verbs: ["get"]
  - apiGroups: ["networking.k8s.io"]
    resources:
      - ingresses
    verbs: ["get", "list", "watch"]
  - nonResourceURLs: ["/metrics"]
    verbs: ["get"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
  labels:
    app: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
  - kind: ServiceAccount
    name: prometheus
    namespace: iot-meter

---
# Prometheus scrape configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: iot-meter
  labels:
    app: prometheus
    app.kubernetes.io/part-of: iot-meter
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
      scrape_timeout: 10s

    alerting:
      alertmanagers:
        - static_configs:
            - targets: ['alertmanager:9093']

    rule_files:
      - '/etc/prometheus/alert_rules.yml'

    scrape_configs:

      # Prometheus self-monitoring
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']

      # Device Manager REST API — /metrics via prometheus_flask_instrumentator
      - job_name: 'device-manager'
        metrics_path: /metrics
        scrape_interval: 10s
        static_configs:
          - targets: ['device-manager:8080']

      # MQTT Collector — /metrics on health port 8081
      - job_name: 'mqtt-collector'
        metrics_path: /metrics
        scrape_interval: 10s
        static_configs:
          - targets: ['mqtt-collector:8081']

      # kube-state-metrics — Kubernetes cluster state
      - job_name: 'kube-state-metrics'
        scrape_interval: 30s
        static_configs:
          - targets: ['kube-state-metrics:8080']

      # Kubernetes pod discovery (auto-scrape pods with prometheus.io annotations)
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names: ['iot-meter']
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: kubernetes_pod_name

  alert_rules.yml: |
    # Prometheus alerting rules for IoT Meter platform
    groups:
      - name: service_health
        rules:
          - alert: ServiceDown
            expr: up{job=~"device-manager|mqtt-collector"} == 0
            for: 2m
            labels:
              severity: critical
              service: '{{ $labels.job }}'
            annotations:
              summary: '{{ $labels.job }} is DOWN'
              description: 'Prometheus cannot scrape {{ $labels.job }} ({{ $labels.instance }}) for more than 2 minutes.'

          - alert: MQTTBrokerDisconnected
            expr: mqtt_collector_mqtt_connected == 0
            for: 1m
            labels:
              severity: critical
              service: mqtt-collector
            annotations:
              summary: 'MQTT collector lost broker connection'
              description: 'mqtt_collector_mqtt_connected has been 0 for >1m.'

          - alert: InfluxDBDown
            expr: mqtt_collector_influxdb_ready == 0
            for: 2m
            labels:
              severity: critical
              service: mqtt-collector
            annotations:
              summary: 'InfluxDB is not reachable from collector'
              description: 'mqtt_collector_influxdb_ready == 0 for >2m.'

          - alert: MinIODown
            expr: mqtt_collector_minio_ready == 0
            for: 2m
            labels:
              severity: critical
              service: mqtt-collector
            annotations:
              summary: 'MinIO is not reachable from collector'
              description: 'mqtt_collector_minio_ready == 0 for >2m.'

      - name: api_performance
        rules:
          - alert: HighErrorRate
            expr: >
              sum(rate(http_requests_total{job="device-manager", status=~"5.."}[5m]))
              /
              sum(rate(http_requests_total{job="device-manager"}[5m]))
              > 0.05
            for: 5m
            labels:
              severity: warning
              service: device-manager
            annotations:
              summary: 'Device Manager error rate above 5%'
              description: 'HTTP 5xx rate is {{ $value | humanizePercentage }}.'

          - alert: HighLatencyP95
            expr: >
              histogram_quantile(0.95,
                sum by (le) (rate(http_request_duration_seconds_bucket{job="device-manager"}[5m]))
              ) > 2
            for: 5m
            labels:
              severity: warning
              service: device-manager
            annotations:
              summary: 'Device Manager p95 latency above 2s'
              description: 'p95 request latency is {{ $value | humanizeDuration }}.'

          - alert: InfluxDBQuerySlow
            expr: >
              rate(device_manager_influxdb_query_duration_seconds_sum[5m])
              /
              rate(device_manager_influxdb_query_duration_seconds_count[5m])
              > 1
            for: 5m
            labels:
              severity: warning
              service: device-manager
            annotations:
              summary: 'InfluxDB queries averaging above 1s'
              description: 'Average InfluxDB query time is {{ $value | humanizeDuration }}.'

      - name: mqtt_pipeline
        rules:
          - alert: HighSequenceGaps
            expr: rate(mqtt_collector_sequence_gaps_total[5m]) > 0.5
            for: 10m
            labels:
              severity: warning
              service: mqtt-collector
            annotations:
              summary: 'Frequent MQTT sequence gaps detected'
              description: 'Sequence gap rate is {{ $value }}/s.'

          - alert: MQTTProcessingErrors
            expr: sum(rate(mqtt_collector_messages_errors_total[5m])) > 0.1
            for: 5m
            labels:
              severity: warning
              service: mqtt-collector
            annotations:
              summary: 'MQTT message processing errors detected'
              description: 'Error rate is {{ $value }}/s.'

      - name: device_alerts
        rules:
          - alert: UnacknowledgedAlertsPiling
            expr: device_manager_alerts_unacknowledged > 10
            for: 15m
            labels:
              severity: warning
              service: device-manager
            annotations:
              summary: 'More than 10 unacknowledged device alerts'
              description: '{{ $value }} unacknowledged alerts pending for >15m.'

      - name: kubernetes
        rules:
          - alert: PodCrashLooping
            expr: increase(kube_pod_container_status_restarts_total{namespace="iot-meter"}[1h]) > 3
            for: 5m
            labels:
              severity: critical
              service: '{{ $labels.pod }}'
            annotations:
              summary: 'Pod {{ $labels.pod }} is crash-looping'
              description: '{{ $labels.pod }} has restarted {{ $value }} times in the last hour.'

          - alert: DeploymentReplicasMismatch
            expr: >
              kube_deployment_status_replicas_available{namespace="iot-meter"}
              !=
              kube_deployment_spec_replicas{namespace="iot-meter"}
            for: 10m
            labels:
              severity: warning
              service: '{{ $labels.deployment }}'
            annotations:
              summary: 'Deployment {{ $labels.deployment }} has unavailable replicas'
              description: 'Replica mismatch detected.'

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: iot-meter
  labels:
    app: prometheus
    app.kubernetes.io/part-of: iot-meter
spec:
  replicas: 1
  selector:
    matchLabels:
      app: prometheus
  strategy:
    type: Recreate          # Single replica — recreate to avoid PVC conflicts
  template:
    metadata:
      labels:
        app: prometheus
    spec:
      serviceAccountName: prometheus
      securityContext:
        fsGroup: 65534      # nobody — Prometheus runs as nobody
        runAsNonRoot: true
        runAsUser: 65534
      containers:
        - name: prometheus
          image: prom/prometheus:v3.4.1
          args:
            - '--config.file=/etc/prometheus/prometheus.yml'
            - '--storage.tsdb.path=/prometheus'
            - '--storage.tsdb.retention.time=90d'
            - '--web.enable-otlp-receiver'
            - '--web.enable-lifecycle'
            - '--web.console.libraries=/etc/prometheus/console_libraries'
            - '--web.console.templates=/etc/prometheus/consoles'
          ports:
            - containerPort: 9090
              name: http
          volumeMounts:
            - name: config
              mountPath: /etc/prometheus
            - name: data
              mountPath: /prometheus
          startupProbe:
            httpGet:
              path: /-/ready
              port: 9090
            initialDelaySeconds: 5
            periodSeconds: 5
            failureThreshold: 12
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: 9090
            initialDelaySeconds: 15
            periodSeconds: 15
            timeoutSeconds: 5
            failureThreshold: 3
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 9090
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
          resources:
            requests:
              cpu: 100m
              memory: 256Mi
            limits:
              cpu: 500m
              memory: 1Gi
      volumes:
        - name: config
          configMap:
            name: prometheus-config
        - name: data
          emptyDir: {}       # Use PV in prod overlay

---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: iot-meter
  labels:
    app: prometheus
    app.kubernetes.io/part-of: iot-meter
spec:
  ports:
    - name: http
      port: 9090
      targetPort: http
  selector:
    app: prometheus
